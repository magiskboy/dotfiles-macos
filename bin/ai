#!/usr/bin/env python3

import os
import re
import sys
import argparse
import requests
import json
from functools import cache
from pygments.lexers import find_lexer_class_by_name
from pygments.formatters.terminal import TerminalFormatter
from pygments import highlight

OLLAMA_URL = os.getenv("AI_OLLAMA_URL", 'http://localhost:11434')

DEFAULT_LEXER = find_lexer_class_by_name("markdown")()

@cache
def get_lexer_by_name(name):
    lexer = find_lexer_class_by_name(name)
    if lexer:
        return lexer()

    return DEFAULT_LEXER


def _reply(prompt, model):
    url = f"{OLLAMA_URL}/api/generate"
    payload = {
        "prompt": prompt + "Note: don't format markdown",
        "model": model,
    }
    response = requests.post(url, json=payload, stream=True)
    response.raise_for_status()

    for line in response.iter_lines():
        data = json.loads(line)
        if data.get("done"):
            break

        yield data.get("response")

def _chunk(generator, live):
    buffer = ""
    for chunk in generator:
        buffer += chunk
        if live:
            while "\n" in buffer:
                line, buffer = buffer.split("\n", 1)
                yield line

    if buffer:
        yield buffer

    return


def _highlight(generator):
    formatter = TerminalFormatter()
    lexer = DEFAULT_LEXER

    for text in generator:
        start_code_block = re.match(r'```(?P<lang>\w+)', text)
        if start_code_block:
            lang = start_code_block.group("lang")
            lexer = get_lexer_by_name(lang)
            continue
        elif text == '```':
            lexer = DEFAULT_LEXER
            continue

        if lexer:
            line = highlight(text, lexer, formatter)
        else:
            line = text + "\n"

        yield line


def main():
    parser = argparse.ArgumentParser(
        description='Generate text using the OLLAMA API',
    )
    parser.add_argument(
        'prompt',
        type=str,
        help='Prompt to generate text from',
    )
    parser.add_argument(
        '--model',
        default='llama3.2:3b',
        help='Model to use for text generation',
    )
    parser.add_argument(
        '--live',
        type=bool,
        required=False,
        default=True,
        help='Live mode',
    )
    args = parser.parse_args()

    for text in _highlight(_chunk(_reply(args.prompt, args.model), args.live)):
        sys.stdout.write(text)

if __name__ == '__main__':
    main()
 
